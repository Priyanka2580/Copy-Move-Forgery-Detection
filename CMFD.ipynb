{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjiSbjx1H1h3"
   },
   "source": [
    "Import\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6608,
     "status": "ok",
     "timestamp": 1747322282995,
     "user": {
      "displayName": "Asutosh_project",
      "userId": "08178536979202645936"
     },
     "user_tz": -330
    },
    "id": "ad9gXIliKuWj",
    "outputId": "94714619-cb29-4942-c2ee-1cec044d47fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import progressbar\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image, ImageFilter\n",
    "from scipy.fftpack import dct  # For DCT\n",
    "from skimage.feature import hog  # For HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ugc0OlTCXXlV"
   },
   "outputs": [],
   "source": [
    "def visualize_result(rgb, gt, pred, figsize=(21, 7), title=None):\n",
    "    \"\"\"Visualize raw input, ground truth, and BusterNet result\"\"\"\n",
    "    pyplot.figure(figsize=figsize)\n",
    "    pyplot.subplot(131)\n",
    "    pyplot.imshow(rgb)\n",
    "    pyplot.title('input image')\n",
    "    pyplot.subplot(132)\n",
    "    pyplot.title('ground truth')\n",
    "    pyplot.imshow(gt)\n",
    "    pyplot.subplot(133)\n",
    "    pyplot.imshow(pred)\n",
    "    pyplot.title('pred')\n",
    "    if title is not None:\n",
    "        pyplot.suptitle(title)\n",
    "\n",
    "\n",
    "def acc_result(gt, pred, display=True):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, F1-score, and balanced accuracy.\n",
    "    \"\"\"\n",
    "    H, W = gt.shape\n",
    "\n",
    "    # Initialize counts\n",
    "    tpc, fpc, tnc, fnc = 0, 0, 0, 0\n",
    "\n",
    "    # Calculate TPC, FPC, TNC, FNC\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            if gt[i, j] == 1 and pred[i, j] == 1:\n",
    "                tpc += 1\n",
    "            elif gt[i, j] == 0 and pred[i, j] == 0:\n",
    "                tnc += 1\n",
    "            elif gt[i, j] == 1 and pred[i, j] == 0:\n",
    "                fnc += 1\n",
    "            elif gt[i, j] == 0 and pred[i, j] == 1:\n",
    "                fpc += 1\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    recall = tpc / (tpc + fnc) if (tpc + fnc) != 0 else 0\n",
    "    precision = tpc / (tpc + fpc) if (tpc + fpc) != 0 else 0\n",
    "    f1_score = 2 * recall * precision / (recall + precision) if (recall + precision) != 0 else 0\n",
    "    tnr = tnc / (tnc + fpc) if (tnc + fpc) != 0 else 0\n",
    "    bal_acc = (recall + tnr) / 2\n",
    "    acc=(tpc+tnc)/(tpc+tnc+fnc+fpc)\n",
    "    # Display results if required\n",
    "    if display:\n",
    "        # Calculate FP, FN, and TP masks for visualization\n",
    "        tp = gt * pred  # True Positives\n",
    "        fp = pred - tp  # False Positives\n",
    "        fn = gt - tp    # False Negatives\n",
    "        tn=(1-gt)*(1-pred) #True Negatives\n",
    "\n",
    "        print(\"Metrics:\")\n",
    "        print(f\"True Positives (TP): {tpc}\")\n",
    "        print(f\"False Positives (FP): {fpc}\")\n",
    "        print(f\"True Negatives (TN): {tnc}\")\n",
    "        print(f\"False Negatives (FN): {fnc}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1_score:.4f}\")\n",
    "        print(f\"Balanced Accuracy: {bal_acc:.4f}\")\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "        # Visualize FP, FN, and TP\n",
    "        pyplot.figure(figsize=(21, 7))\n",
    "        pyplot.subplot(131)\n",
    "        pyplot.imshow(fp, cmap='gray')\n",
    "        pyplot.title('False Positive')\n",
    "        pyplot.subplot(132)\n",
    "        pyplot.imshow(fn, cmap='gray')\n",
    "        pyplot.title('False Negative')\n",
    "        pyplot.subplot(133)\n",
    "        pyplot.imshow(tp, cmap='gray')\n",
    "        pyplot.title('True Positive')\n",
    "        title = f\"Precision = {precision:.4f}, Recall = {recall:.4f}, F1-Score = {f1_score:.4f}, Balanced Accuracy = {bal_acc:.4f}\"\n",
    "        pyplot.suptitle(title)\n",
    "\n",
    "    # Return all metrics\n",
    "    return {\n",
    "        \"TP\": tpc,\n",
    "        \"FP\": fpc,\n",
    "        \"TN\": tnc,\n",
    "        \"FN\": fnc,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1_score,\n",
    "        \"Balanced Accuracy\": bal_acc,\n",
    "        \"Accuracy\": acc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJ1rtMuaH9ud"
   },
   "source": [
    "Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9za1A23LOrz"
   },
   "outputs": [],
   "source": [
    "def read(name, size=256):\n",
    "    img = Image.open(name).convert('L')  # Convert to grayscale\n",
    "    numpydata = np.asarray(img).astype('float') / 255.0  # Normalize to [0, 1]\n",
    "    return numpydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPcD4T-8IEiX"
   },
   "source": [
    "Overlapping Blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnc8thzntNeq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def divideIntoBlocks(gray_image, blockSize=7, stride=1):\n",
    "    \"\"\"\n",
    "    Divides a grayscale image into blocks with a given stride.\n",
    "\n",
    "    Args:\n",
    "        gray_image (numpy.ndarray): Grayscale image as a NumPy array.\n",
    "        blockSize (int): Size of each block (blockSize x blockSize).\n",
    "        stride (int): Step size for moving the block (stride=1 = overlapping, stride=blockSize = non-overlapping).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: List of blocks, each with shape (3, blockSize, blockSize) - (x_coords, y_coords, block_pixels).\n",
    "    \"\"\"\n",
    "    height, width = gray_image.shape\n",
    "    img_blocks = []\n",
    "\n",
    "    for i in range(0, height - blockSize + 1, stride):\n",
    "        for j in range(0, width - blockSize + 1, stride):\n",
    "            indx = np.ones((blockSize, blockSize)) * j  # X-coordinates\n",
    "            indy = np.ones((blockSize, blockSize)) * i  # Y-coordinates\n",
    "            block = np.array([indx, indy, gray_image[i:i + blockSize, j:j + blockSize]])\n",
    "            img_blocks.append(block)\n",
    "\n",
    "    return np.array(img_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6wSvMGRII92"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogz4rzueLN-u"
   },
   "outputs": [],
   "source": [
    "def zigzag_indices(n):\n",
    "    indices = []\n",
    "    for s in range(2 * n - 1):\n",
    "        if s % 2 == 0:\n",
    "            for i in range(s + 1):\n",
    "                j = s - i\n",
    "                if i < n and j < n:\n",
    "                    indices.append((i, j))\n",
    "        else:\n",
    "            for i in range(s + 1):\n",
    "                j = s - i\n",
    "                if j < n and i < n:\n",
    "                    indices.append((j, i))\n",
    "    return indices\n",
    "def dct_feature_extraction(block):\n",
    "    # Step 1: Apply 2D DCT\n",
    "    dct_block = dct(dct(block, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "\n",
    "    # Step 2: Zigzag scan\n",
    "    n = dct_block.shape[0]  # assuming square block\n",
    "    indices = zigzag_indices(n)\n",
    "    zigzag_values = np.array([dct_block[i, j] for i, j in indices])\n",
    "\n",
    "    return zigzag_values[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJWFrEBsIb_2"
   },
   "outputs": [],
   "source": [
    "def hog_feature_extraction(block):\n",
    "    \"\"\"Extract HOG features from a block\"\"\"\n",
    "    # Compute HOG features with 8 bins\n",
    "    hog_features = hog(block, pixels_per_cell=(7, 7), cells_per_block=(1, 1), visualize=False, orientations=8) #orientations is number of bins\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KSrm5DFIc7H"
   },
   "outputs": [],
   "source": [
    "def combined_feature_extraction(block):\n",
    "    #Extract combined DCT and HOG features from a block\n",
    "    dct_features = dct_feature_extraction(block)[:8]  # Ensure length is 8\n",
    "    hog_features = hog_feature_extraction(block)[:8]  # Ensure length is 8\n",
    "    return np.concatenate((dct_features,hog_features))  # Concatenate to match length 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4xabmE1frc-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "def print_first_5_blocks_features(features):\n",
    "    \"\"\"Print first 5 blocks' feature values before shuffling and lexsorting\"\"\"\n",
    "    print(\"\\nFirst 5 blocks' feature values before shuffling:\")\n",
    "    for i in range(min(5, len(features))):\n",
    "        print(f\"Block {i+1} features:\", features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1747322283272,
     "user": {
      "displayName": "Asutosh_project",
      "userId": "08178536979202645936"
     },
     "user_tz": -330
    },
    "id": "Iy2bbHnVfyFp",
    "outputId": "79daf608-e20f-483e-b8db-14acf1bf302e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Shuffle Order: [2, 8, 4, 12, 14, 5, 7, 9, 3, 13, 15, 10, 6, 11, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Replace FIXED_SHUFFLE_ORDERS with a single fixed shuffle order\n",
    "FIXED_SHUFFLE_ORDER = [2, 8, 4, 12, 14, 5, 7, 9, 3, 13, 15, 10, 6, 11, 0, 1]\n",
    "print(\"Fixed Shuffle Order:\", FIXED_SHUFFLE_ORDER)\n",
    "def shuffle_features(features):\n",
    "    \"\"\"Shuffle features using the fixed shuffle order.\"\"\"\n",
    "    shuffled = deepcopy(features)\n",
    "    for block in shuffled:\n",
    "        block[0] = block[0][FIXED_SHUFFLE_ORDER]  # Apply fixed shuffle\n",
    "    return shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQYjDcw2r-sU"
   },
   "source": [
    "Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EVK_D1cr9aS"
   },
   "outputs": [],
   "source": [
    "def calculate_and_store_averages(csv_file_path):\n",
    "    \"\"\"Calculate the average of all metric columns and store them in the CSV file.\"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Calculate the average of each metric column\n",
    "    metric_columns = df.columns[1:]  # Assuming the first column is not a metric\n",
    "    averages = df[metric_columns].mean()\n",
    "\n",
    "    # Append the average values as a new row at the end of the DataFrame\n",
    "    averages_row = pd.DataFrame(averages).T\n",
    "    averages_row.insert(0, df.columns[0], 'Average')  # Insert label for the first column\n",
    "    df = pd.concat([df, averages_row], ignore_index=True)\n",
    "\n",
    "    # Write the updated DataFrame back to the CSV file\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEfAOpsDP9vS"
   },
   "source": [
    "Encode feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3vUuu9ZQBJt"
   },
   "outputs": [],
   "source": [
    "def encode_features(blocks, gray_image, feature_extraction_func):\n",
    "    \"\"\"\n",
    "    Encodes blocks into feature vectors including block coordinates.\n",
    "\n",
    "    Args:\n",
    "        blocks (numpy.ndarray): List of non-overlapping image blocks.\n",
    "        gray_image (numpy.ndarray): Input grayscale image.\n",
    "        feature_extraction_func (function): Feature extraction function (e.g., combined_feature_extraction).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Encoded feature matrix with block features and coordinates.\n",
    "    \"\"\"\n",
    "    bar = progressbar.ProgressBar(max_value=len(blocks)).start()  # Initialize progress bar\n",
    "    features = []  # List to store encoded features\n",
    "\n",
    "    for count, block in enumerate(blocks):\n",
    "        bar.update(count)  # Update progress bar\n",
    "\n",
    "        # Extract block coordinates\n",
    "        blockX = block[0][0][0]  # X-coordinate of the block\n",
    "        blockY = block[1][0][0]  # Y-coordinate of the block\n",
    "\n",
    "        # Copy the grayscale block\n",
    "        block_data = np.copy(block[2])  # Grayscale pixel values\n",
    "\n",
    "        # Extract features using the specified feature extraction function\n",
    "        feature = feature_extraction_func(block_data)[:16]  # Limit to first 16 features\n",
    "\n",
    "        # Create corresponding coordinate values\n",
    "        fX = np.ones(16) * blockX\n",
    "        fY = np.ones(16) * blockY\n",
    "\n",
    "        # Append the feature and coordinates as a single row\n",
    "        features.append(np.array([feature, fX, fY]))\n",
    "\n",
    "    bar.finish()  # Finish progress bar\n",
    "    return np.array(features)  # Convert to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUQy3_qlTr6G"
   },
   "outputs": [],
   "source": [
    "def lexiSort(feaMap):\n",
    "    \"\"\"Lexicographically sorts feature vectors and returns them.\"\"\"\n",
    "    if feaMap.size == 0:  # Check if feaMap is empty\n",
    "        return feaMap  # Return the empty array if it is\n",
    "    onlyfea = feaMap[:, 0]\n",
    "    indx = np.lexsort(np.rot90(onlyfea))\n",
    "    sorted_features = [feaMap[i] for i in indx]\n",
    "    return np.array(sorted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seN20BA0Tz2P"
   },
   "outputs": [],
   "source": [
    "def connectedComp(predout, thresY=0, thresX=0):\n",
    "    w = np.where(predout == 1)\n",
    "    begX = np.min(w[1])\n",
    "    endX = np.max(w[1])\n",
    "    begY = np.min(w[0])\n",
    "    endY = np.max(w[0])\n",
    "    thresX += (endX - begX)\n",
    "    thresY += (endY - begY)\n",
    "    predx = np.copy(predout)\n",
    "    for i in range(begX, endX):\n",
    "        flag = False\n",
    "        lo = begY\n",
    "        for j in range(begY, endY):\n",
    "            if predx[j][i] == 1:\n",
    "                if flag and (j - lo) < thresY // 8:\n",
    "                    predx[lo:j, i] = 1\n",
    "                flag = True\n",
    "                lo = j + 1\n",
    "    predy = np.copy(predout)\n",
    "    for i in range(begY, endY):\n",
    "        flag = False\n",
    "        lo = begX\n",
    "        for j in range(begX, endX):\n",
    "            if predy[i][j] == 1:\n",
    "                if flag and (j - lo) < thresX // 8:\n",
    "                    predy[i, lo:j] = 1\n",
    "                flag = True\n",
    "                lo = j + 1\n",
    "\n",
    "    z = np.clip(predx + predy, 0, 1)\n",
    "\n",
    "    predg = z * 0\n",
    "    for i in range(begY, endY):\n",
    "        for j in range(begX, endX):\n",
    "            if np.sum(z[i - 1:i + 3, j - 1:j + 3]) > 1:\n",
    "                predg[i:i + 4, j:j + 4] = 1\n",
    "    return predg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8AhhZRiTzp6"
   },
   "outputs": [],
   "source": [
    "def analyzeBlocks(blockA, blockB, simThres=0.02, shuffle_idx=0):\n",
    "    \"\"\"\n",
    "    Analyze two blocks to determine if they are similar.\n",
    "    Now uses ONLY MAX difference calculation (other methods are commented out).\n",
    "    \"\"\"\n",
    "    dx = blockA[1][0] - blockB[1][0]\n",
    "    dy = blockA[2][0] - blockB[2][0]\n",
    "    dist = math.sqrt(pow(dx, 2) + pow(dy, 2))\n",
    "\n",
    "    # ===== FEATURE DIFFERENCE CALCULATION =====\n",
    "    # 1. Original approach (sum of all features) - COMMENTED OUT\n",
    "    fA = np.sum(blockA[0])\n",
    "    fB = np.sum(blockB[0])\n",
    "    dif = abs(fA - fB)\n",
    "\n",
    "    # 2. Alternative approach (mean absolute difference) - COMMENTED OUT\n",
    "    # dif = np.mean(np.abs(blockA[0] - blockB[0]))\n",
    "\n",
    "    # 3. MAX absolute difference (ACTIVE)\n",
    "    #dif = np.max(np.abs(blockA[0] - blockB[0]))\n",
    "\n",
    "    # ===== THRESHOLD AND DISTANCE CHECK =====\n",
    "    # Fixed threshold (no shuffle-based adjustment)\n",
    "    adjusted_threshold = simThres * 1.0\n",
    "\n",
    "    # Fixed minimum distance (no shuffle-based adjustment)\n",
    "    min_dist = 10\n",
    "\n",
    "    # Create result array with coordinates\n",
    "    res = np.array([\n",
    "        blockA[1][0],  # xa\n",
    "        blockA[2][0],  # ya\n",
    "        blockB[1][0],  # xb\n",
    "        blockB[2][0],  # yb\n",
    "        abs(dx),       # offsetX\n",
    "        abs(dy),       # offsetY\n",
    "    ])\n",
    "\n",
    "    if dif < adjusted_threshold and dist >= min_dist:\n",
    "        return res\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uk9l5O1nEh1N"
   },
   "outputs": [],
   "source": [
    "def detectSimi_with_shuffles(gray_image, gt, blockSize=7, feature_extraction_func=combined_feature_extraction):\n",
    "    \"\"\"Detect similarities using Shuffle 3's logic (max difference) with original output format.\"\"\"\n",
    "    shapeA, shapeB = gray_image.shape\n",
    "    blocks = divideIntoBlocks(gray_image, blockSize)\n",
    "    features = encode_features(blocks, gray_image, feature_extraction_func)\n",
    "\n",
    "    # Print first 5 blocks' features before shuffling (original diagnostic)\n",
    "    print(\"\\nFirst 5 blocks' feature values before shuffling:\")\n",
    "    for i in range(min(5, len(features))):\n",
    "        print(f\"Block {i+1} features:\", features[i][0])\n",
    "\n",
    "    # Apply fixed shuffle (Shuffle 3's order)\n",
    "    shuffled_features = shuffle_features(features)\n",
    "    lsorted = lexiSort(shuffled_features)\n",
    "\n",
    "    # Print sample after shuffling (original diagnostic)\n",
    "    print(\"\\nSample of first sorted block after shuffling:\")\n",
    "    print(lsorted[0][0][:5])  # First 5 features of first block\n",
    "\n",
    "    vectors = []\n",
    "    windowSize = 3  # Shuffle 3 used windowSize=5 (3 + shuffle_idx=2)\n",
    "\n",
    "    # Block comparison with Shuffle 3's max-difference logic\n",
    "    for i in range(len(lsorted) - windowSize + 1):\n",
    "        for j in range(1, windowSize):\n",
    "            blockA, blockB = np.copy(lsorted[i]), np.copy(lsorted[i + j])\n",
    "            res = analyzeBlocks(blockA, blockB, simThres=0.002, shuffle_idx=2)  # shuffle_idx=2 for Shuffle 3\n",
    "            if res is not None:\n",
    "                vectors.append(res)\n",
    "\n",
    "    print(f\"\\nNumber of similar vectors found: {len(vectors)}\")\n",
    "\n",
    "    # Original shift map calculation\n",
    "    shift = np.zeros((shapeA, shapeB))\n",
    "    for vector in vectors:\n",
    "        shift[int(vector[5])][int(vector[4])] += 1\n",
    "\n",
    "    maxoff = np.max(shift)\n",
    "    offsetThreshold = max(1, 3 * maxoff // 4)  # Shuffle 3 used 4/5 of maxoff\n",
    "\n",
    "    offset = np.copy(shift).astype(int)\n",
    "    offset[offset <= offsetThreshold] = 0\n",
    "    offset[offset > offsetThreshold] = 1\n",
    "\n",
    "    duplicates = [vec for vec in vectors if offset[int(vec[5])][int(vec[4])] == 1]\n",
    "    print(f\"Number of detected duplicates: {len(duplicates)}\")\n",
    "\n",
    "    # Generate final mask (original logic)\n",
    "    final = gray_image * 0\n",
    "    for res in duplicates:\n",
    "        final[int(res[1])][int(res[0])] = 1\n",
    "        final[int(res[3])][int(res[2])] = 1\n",
    "\n",
    "    # Shuffle 3's post-processing parameters\n",
    "    thresY = 0  # shuffle_idx=2 → 2*2=4\n",
    "    thresX = 0\n",
    "    predMask = connectedComp(final, thresY=thresY, thresX=thresX)\n",
    "\n",
    "    kernel_size = 4  # 4 + shuffle_idx=2 → 6\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    predOut = cv2.dilate(predMask, kernel, iterations=2)\n",
    "\n",
    "    kernel0_size = 3  # 3 + shuffle_idx=2 → 5\n",
    "    kernel0 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel0_size, kernel0_size))\n",
    "    predOut2 = cv2.erode(predMask, kernel0, iterations=1)\n",
    "\n",
    "    min_size = 10  # 10 - shuffle_idx=2 → 8\n",
    "    if np.sum(np.round(np.clip(predOut2, 0, 1))) < min_size:\n",
    "        predOut = predOut * 0\n",
    "\n",
    "    # Original visualization and metrics\n",
    "    rgb_image = np.stack([gray_image]*3, axis=-1)\n",
    "    visualize_result(rgb_image, gt, predOut, title=\"Shuffle 1 (Sum)\")\n",
    "    metrics = acc_result(gt, predOut, display=True)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8WInfE8Iiac"
   },
   "source": [
    "Process Image from Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LF7xI_Jd0dMW"
   },
   "outputs": [],
   "source": [
    "def process_images_from_drive(folder_path, output_csv='dct+hog_7_shuffled.csv', blockSize=7, feature_extraction_func=combined_feature_extraction):\n",
    "    \"\"\"Process images with a single fixed shuffle order.\"\"\"\n",
    "    results = []\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    forged_files = [f for f in files if '_F.' in f]\n",
    "    gt_files = [f for f in files if '_B.' in f]\n",
    "\n",
    "    forged_files.sort()\n",
    "    gt_files.sort()\n",
    "\n",
    "    if len(forged_files) != len(gt_files):\n",
    "        print(\"Error: Forged and ground truth files do not match.\")\n",
    "        return\n",
    "\n",
    "    for forged_file, gt_file in zip(forged_files, gt_files):\n",
    "        forged_path = os.path.join(folder_path, forged_file)\n",
    "        gt_path = os.path.join(folder_path, gt_file)\n",
    "\n",
    "        gray_image = read(forged_path)\n",
    "        gt = read(gt_path)\n",
    "\n",
    "        if len(gt.shape) == 3:\n",
    "            gt = gt[:, :, 0]  # Ensure single channel\n",
    "\n",
    "        print(f\"\\n\\n{'='*80}\")\n",
    "        print(f\"Processing {forged_file} and {gt_file}...\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        metrics = detectSimi_with_shuffles(\n",
    "            gray_image, gt,\n",
    "            blockSize=blockSize,\n",
    "            feature_extraction_func=feature_extraction_func\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"File Name\": forged_file,\n",
    "            \"True Positives (TP)\": metrics[\"TP\"],\n",
    "            \"False Positives (FP)\": metrics[\"FP\"],\n",
    "            \"True Negatives (TN)\": metrics[\"TN\"],\n",
    "            \"False Negatives (FN)\": metrics[\"FN\"],\n",
    "            \"Precision\": metrics[\"Precision\"],\n",
    "            \"Recall\": metrics[\"Recall\"],\n",
    "            \"F1-Score\": metrics[\"F1-Score\"],\n",
    "            \"Accuracy\": metrics[\"Accuracy\"],\n",
    "            \"Balanced Accuracy\": metrics[\"Balanced Accuracy\"]\n",
    "        })\n",
    "\n",
    "        pd.DataFrame(results).to_csv(output_csv, index=False)\n",
    "        print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "    calculate_and_store_averages(output_csv)\n",
    "    print(f\"Final results with averages saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1bbGuOid3MJC6PGV9qFVmIAEC3GYg9WPK"
    },
    "executionInfo": {
     "elapsed": 2469554,
     "status": "ok",
     "timestamp": 1747324753750,
     "user": {
      "displayName": "Asutosh_project",
      "userId": "08178536979202645936"
     },
     "user_tz": -330
    },
    "id": "pKhsowz2la5_",
    "outputId": "7de76397-e985-4e87-b95b-2476c71710b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the folder path containing images\n",
    "folder_path = '/content/drive/MyDrive/Project/COMOFOD-40'  # Update this path\n",
    "\n",
    "# Process images and save results to CSV\n",
    "process_images_from_drive(folder_path, output_csv='dct+hog_7_shuffled.csv',\n",
    "                         blockSize=7, feature_extraction_func=combined_feature_extraction)\n",
    "\n",
    "# Download the results CSV file\n",
    "from google.colab import files\n",
    "files.download('dct+hog_7_shuffled.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPjJ9qQ0TbmK2NFOBso3BG6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
